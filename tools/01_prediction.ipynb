{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict notebook pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "# Python imports\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from barbar import Bar\n",
    "from natsort import natsorted\n",
    "import time\n",
    "\n",
    "from models import UNet, init_net\n",
    "from dataloader import EndoMaskDataset\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "# For experimentation purpose\n",
    "import torch\n",
    "import torchvision\n",
    "import albumentations as alb\n",
    "from torchsummary import summary\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import albumentations.augmentations.transforms as alb_tr\n",
    "\n",
    "# Project imports\n",
    "import utils as ut\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(1)\n",
    "DEVICE = torch.device('cuda:0')\n",
    "\n",
    "# Setup interact widget\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Auto-reload magic function setup\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Matplotlib magic function setup\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and the trained experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set weights dir and tb dir\n",
    "load_epoch = 200\n",
    "exp_dir = \"\"  # path to exp dir\n",
    "model_path = os.path.join(exp_dir, \"model_weights\", \"weights_{}\".format(str(load_epoch)))\n",
    "\n",
    "exp_name = pathlib.Path(exp_dir).name    \n",
    "with open(os.path.join(config_file), 'r') as configfile:\n",
    "    exp_opts = json.load(configfile)\n",
    "    print(\"Loaded experiment configs!\")\n",
    "    \n",
    "model = Unet().to(device)\n",
    "checkpoint = torch.load()  # path to the checkpoint file that ends with ' .pt'\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can predict on the val file if you are not using the val loss for early stopping\n",
    "# Or you can specify a separate test file\n",
    "split_file_path = \"../aicm_sim_dataset/fold_1/{}_files.txt\"\n",
    "predict_filenames = ut.read_lines_from_text_file(split_file_path.format(\"val\"))\n",
    "\n",
    "\n",
    "HEIGHT = 448  # This is just a default, change this as per needed\n",
    "WIDTH = 448\n",
    "DATAROOT = \"/mnt/sds-stud/guest/data_preprocessed/data_coco_final_v3\"  # An example, you can change this later\n",
    "\n",
    "predict_dataset = EndoMaskDataset(data_root_folder=DATAROOT,\n",
    "                                  filenames=predict_filenames,\n",
    "                                  height=HEIGHT,\n",
    "                                  width=WIDTH,\n",
    "                                  image_aug=None,\n",
    "                                  image_mask_aug=None)\n",
    "\n",
    "predict_dataloader = DataLoader(predict_dataset,\n",
    "                                batch_size=1,\n",
    "                                shuffle=False,\n",
    "                                drop_last=False)\n",
    "\n",
    "#----------------------------------------------------------------#\n",
    "# If you want to visualise a random sample or a specified sample from the prediction data, \n",
    "# you can use this code, else comment it out\n",
    "index = np.random.choice(dataset.__len__(), 1)\n",
    "image, mask = dataset.__getitem__(index[0])\n",
    "image, mask = map(process_utils.convert_to_numpy_image, (image, mask))\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (40, 20)\n",
    "\n",
    "plt.subplot(1, 3, 1) \n",
    "plt.imshow(image)\n",
    "\n",
    "plt.subplot(1, 3, 2) \n",
    "plt.imshow(np.squeeze(mask))  \n",
    "\n",
    "plt.subplot(1, 3, 3) \n",
    "plt.imshow(image+mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, gt_masks, pred_masks = [], [], []\n",
    "epoch_metric = 0\n",
    "metrics = []\n",
    "\n",
    "for i, batch in enumerate(Bar(predict_dataloader), 0):\n",
    "    image, gt_mask, _ = batch\n",
    "    image_input, gt_mask = image.to(device), gt_mask.to(device)\n",
    "    pred_mask = model(image_input)   # gaussian  is the output from model\n",
    "    \n",
    "    metric = mse(pred=pred_mask, target=gt_mask)\n",
    "    \n",
    "    # You can directly use the save_image function of pytorch that saves the tensors as png images\n",
    "    # Just have to specify all the paths here\n",
    "    if save_png:\n",
    "        save_image(image_input, os.path.join(save_image_path, \"{:06d}.png\".format(i + 1)))\n",
    "        save_image(gt_mask, os.path.join(save_gt_mask_path, \"{:06d}.png\".format(i + 1)))\n",
    "        save_image(pred_mask, os.path.join(save_pred_mask_path, \"{:06d}.png\".format(i + 1)))\n",
    "    \n",
    "    images.append(image.detach().cpu().clone().numpy().transpose((0, 2, 3, 1)))\n",
    "    gt_masks.append(gt_mask.detach().cpu().clone().numpy().transpose((0, 2, 3, 1)))\n",
    "    pred_masks.append(pred_mask.detach().cpu().clone().numpy().transpose((0, 2, 3, 1)))\n",
    "    metrics.append(metric.item())\n",
    "\n",
    "    \n",
    "# Here you get the images, gt and pred as np arrays and then \n",
    "# you can do whatever you want with it\n",
    "images = np.concatenate(images)\n",
    "gt_masks = np.concatenate(gt_masks)\n",
    "pred_masks = np.concatenate(pred_masks)\n",
    "\n",
    "print(\"Evaluation completed. Metric score: {} %\".format(np.mean(metrics)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (40, 20)\n",
    "\n",
    "plt.subplot(1, 3, 1) \n",
    "plt.imshow(images[index[0]])\n",
    "\n",
    "plt.subplot(1, 3, 2) \n",
    "plt.imshow(np.squeeze(pred_masks[index[0]]))  \n",
    "\n",
    "plt.subplot(1, 3, 3) \n",
    "plt.imshow(images[index[0]]+pred_masks[index[0]])\n",
    "\n",
    "#plt.savefig(\"...pred.png\")  # use if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute any metrics using the np arrays...\n",
    "# Visualise the metrics...\n",
    "# Save metrics to disk..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* End of program"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deeplearning-sandbox]",
   "language": "python",
   "name": "conda-env-deeplearning-sandbox-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
