{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train notebook pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "# Python imports\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from barbar import Bar\n",
    "from natsort import natsorted\n",
    "import time\n",
    "\n",
    "from models import UNet, init_net\n",
    "from dataloader import EndoMaskDataset\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "# For experimentation purpose\n",
    "import torch\n",
    "import torchvision\n",
    "import albumentations as alb\n",
    "from torchsummary import summary\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import albumentations.augmentations.transforms as alb_tr\n",
    "\n",
    "# Project imports\n",
    "import utils as ut\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(1)\n",
    "DEVICE = torch.device('cuda:0')\n",
    "\n",
    "# Setup interact widget\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Auto-reload magic function setup\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Matplotlib magic function setup\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load path to text file\n",
    "# You could automate this with an argument possibly ,if needed like just specifying a fold number\n",
    "split_file_path = \"../aicm_sim_dataset/fold_1/{}_files.txt\"\n",
    "train_filenames = ut.read_lines_from_text_file(split_file_path.format(\"train\"))\n",
    "\n",
    "# If you want to turn off augmentation then just set this False, \n",
    "# so you don't have to instantiate aug variables all the time\n",
    "aug = True \n",
    "\n",
    "\n",
    "HEIGHT = 448  # This is just a default, change this as per needed\n",
    "WIDTH = 448\n",
    "AUG_PROB = 0.5  # Randomness with which the random aug has to be implemented\n",
    "\n",
    "\n",
    "# Define aug on image\n",
    "# and the aug to be done on both image and mask\n",
    "if aug:\n",
    "    image_aug = alb.Compose([alb.Resize(height=HEIGHT, width=WIDTH),\n",
    "                             alb_tr.ColorJitter(brightness=0.2,\n",
    "                                                contrast=(0.3, 1.5),\n",
    "                                                saturation=(0.5, 2),\n",
    "                                                hue=0.1,\n",
    "                                                p=AUG_PROB)])\n",
    "                             \n",
    "    image_mask_aug = alb.Compose([alb.Rotate(limit=(-60, 60), p=AUG_PROB),\n",
    "                                  alb.IAAAffine(translate_percent=10, shear=0.1, p=AUG_PROB),\n",
    "                                  alb.HorizontalFlip(p=AUG_PROB),\n",
    "                                  alb.VerticalFlip(p=AUG_PROB)])\n",
    "\n",
    "else:\n",
    "    image_aug = None\n",
    "    image_mask_aug = None\n",
    "\n",
    "    \n",
    "DATAROOT = \"/mnt/sds-stud/guest/data_preprocessed/data_coco_final_v3\"  # An example, you can change this later\n",
    "MASK_PATH = \"mask\"  # Whatever this path is \n",
    "\n",
    "# Instantiate PyTorch dataloader\n",
    "train_dataset = EndoMaskDataset(data_root_folder=DATAROOT,\n",
    "                                     filenames=train_filenames,\n",
    "                                     height=HEIGHT,\n",
    "                                     width=WIDTH,\n",
    "                                     image_aug=image_aug,\n",
    "                                     image_mask_aug=image_mask_aug)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Package this into a pytorch dataloader\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True,\n",
    "                              drop_last=False)\n",
    "\n",
    "VAL = True  # If you don't want val just toggle this flag\n",
    "\n",
    "if VAL:\n",
    "    val_filenames = ut.read_lines_from_text_file(split_file_path.format(\"val\"))\n",
    "    \n",
    "    val_dataset = EndoMaskDataset(data_root_folder=DATAROOT,\n",
    "                                  filenames=val_filenames,\n",
    "                                  height=HEIGHT,\n",
    "                                  width=WIDTH,\n",
    "                                  image_aug=None,\n",
    "                                  image_mask_aug=None)\n",
    "\n",
    "\n",
    "    val_dataloader = DataLoader(val_dataset,\n",
    "                                batch_size=BATCH_SIZE,\n",
    "                                shuffle=False,\n",
    "                                drop_last=False)\n",
    "\n",
    "# Save image augmentations to config file\n",
    "aug_dict = {\"image_aug\": alb.to_dict(image_aug) if image_aug else None,\n",
    "            \"image_mask_aug\": alb.to_dict(image_mask_aug) if image_mask_aug else None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed everything\n",
    "seed = 10\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Create model, optim and scheduler\n",
    "model = UNet(n_channels=3,  # Input channels\n",
    "             n_classes=1)  # Output channels\n",
    "\n",
    "LR = 0.001 # Learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
    "                                                               patience=10,\n",
    "                                                               min_lr=1e-10,\n",
    "                                                               factor=0.1)\n",
    "\n",
    "# Init model\n",
    "model = init_net(model, type=\"kaiming\", mode=\"fan_in\",\n",
    "                 activation_mode=\"relu\",\n",
    "                 distribution=\"normal\")\n",
    "\n",
    "\"\"\"\n",
    "Loss functions\n",
    "\"\"\"\n",
    "mse = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_epoch(dataloader, train=True):\n",
    "    running_loss = 0\n",
    "    running_metric = 0\n",
    "    pred_mask = None\n",
    "\n",
    "    if train:\n",
    "        model.train()\n",
    "\n",
    "    for i, batch in enumerate(Bar(dataloader), 0):\n",
    "        image, mask, filename = batch\n",
    "        image, mask = image.to(DEVICE), mask.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()  # set the gradients to zero\n",
    "        pred_mask = model(image)\n",
    "        loss = mse(y_pred=pred_mask, y_true=mask)\n",
    "\n",
    "        if train:\n",
    "            loss.backward()  # backward pass\n",
    "            optimizer.step()  # Update parameters\n",
    "\n",
    "        metric = metric_fn(pred=pred_mask, target=mask)\n",
    "        running_metric += metric.item() * BATCH_SIZE\n",
    "        running_loss += loss.item() * BATCH_SIZE  # Mean of one batch times the batch size\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)  # Sum of all samples over number of samples in dataset\n",
    "    epoch_metric = (running_metric * 100) / len(dataloader.dataset)\n",
    "    return epoch_loss, epoch_metric, pred_mask[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_PATH = \"\" # Set a log path here\n",
    "writer = SummaryWriter(LOG_PATH)\n",
    "MODEL_NAME = \"unet_baseline\"\n",
    "\n",
    "def log_losses(name, loss, epoch):\n",
    "    \"\"\"Write an event to the tensorboard events file\"\"\"\n",
    "    if isinstance(loss, dict): writer.add_scalars(name, loss, epoch)\n",
    "    else: writer.add_scalar(name, loss, epoch)\n",
    "\n",
    "def log_images(name, loss, epoch):\n",
    "    \"\"\"Write an image to the tensorboard events file\"\"\"\n",
    "    writer.add_image(name, loss, epoch)\n",
    "\n",
    "def save_model(epoch):\n",
    "    \"\"\"Save model weights to disk\n",
    "    \"\"\"\n",
    "    save_folder = os.path.join(LOG_PATH, \"model_weights\", \"weights_{}\".format(epoch))\n",
    "    os.makedirs(save_folder)\n",
    "    save_path = os.path.join(save_folder, \"{}.pth\".format(MODEL_NAME))\n",
    "    to_save = model.state_dict()\n",
    "    torch.save(to_save, save_path)\n",
    "\n",
    "def save_checkpoint(self, epoch, loss):\n",
    "    \"\"\" Save model weights and optim state to disk\n",
    "    \"\"\"\n",
    "    save_folder = os.path.join(LOG_PATH, \"model_weights\", \"weights_{}\".format(epoch))\n",
    "    os.makedirs(save_folder)\n",
    "    save_path = os.path.join(save_folder, \"{}.pt\".format(MODEL_NAME))\n",
    "    checkpoint = {'epoch': epoch,\n",
    "                  'model_state_dict': model.state_dict(),\n",
    "                  'optimizer_state_dict': optimizer.state_dict(),\n",
    "                  'loss': loss}\n",
    "    torch.save(checkpoint, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 60\n",
    "SAVE_FREQ = 10  # Save every n epochs\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(\"Epoch {}\".format(epoch + 1))\n",
    "\n",
    "    model.train()\n",
    "    time_before_epoch_train = time.time()\n",
    "    # *** Train loop ***\n",
    "    # *** Train loop ***\n",
    "    train_loss, train_metric, train_pred = compute_epoch(dataloader=train_dataloader, train=True)\n",
    "    lr_scheduler.step(train_loss)\n",
    "    # *** End train loop ***\n",
    "    epoch_train_duration = time.time() - time_before_epoch_trai\n",
    "    \n",
    "    log_losses('loss', {\"train_loss\": train_loss}, epoch+1)\n",
    "    log_losses('train_metric', train_metric, epoch+1)\n",
    "    log_images('train', train_pred, epoch+1)\n",
    "    print('Epoch {} mean batch train loss: {:0.5f} | train metric: {:0.4f} | epoch train time: {:0.2f}s'.\n",
    "          format(epoch+1, train_loss, train_metric, epoch_train_duration))\n",
    "\n",
    "    if VAL:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            time_before_epoch_val = time.time()\n",
    "            # *** Val loop ***\n",
    "            val_loss, val_metric, val_pred = self.compute_epoch(dataloader=self.val_dataloader, train=False)\n",
    "            # *** End val loop ***\n",
    "            epoch_val_duration = time.time() - time_before_epoch_val\n",
    "\n",
    "        self.log_losses('loss', {\"val_loss\": val_loss}, epoch + 1)\n",
    "        print('Epoch {} mean batch val loss: {:0.5f} | val metric: {:0.4f} | val train time: {:0.2f}s'.\n",
    "              format(epoch+1, val_loss, val_metric, epoch_val_duration))\n",
    "\n",
    "    # save model checkpoint every save_freq epochs\n",
    "    if (epoch + 1) % SAVE_FREQ == 0: save_checkpoint(epoch=epoch+1, loss=train_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* End of program"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deeplearning-sandbox]",
   "language": "python",
   "name": "conda-env-deeplearning-sandbox-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
