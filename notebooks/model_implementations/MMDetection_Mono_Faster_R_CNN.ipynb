{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wy4A5DNaOVEB"
      },
      "source": [
        "# PDSM Stereo Faster R-CNN\n",
        "@author: Moritz Bednorz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFXHaf7rOi-l"
      },
      "source": [
        "## 1 - Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nVrx6JHOodK"
      },
      "source": [
        "### 1.1 - Install packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wmT8v-cE9Am",
        "outputId": "2a77bfef-80ed-4627-d1e6-903b0a89daa7"
      },
      "outputs": [],
      "source": [
        "# Check nvcc version\n",
        "!nvcc -V\n",
        "# Check GCC version\n",
        "!gcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZT_baA4HJ2K7",
        "outputId": "d6ff294f-de49-4e32-9ddf-9755f3777ea4"
      },
      "outputs": [],
      "source": [
        "# install dependencies: (use cu111 because colab has CUDA 11.1)\n",
        "!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9in4tl_ajJ74",
        "outputId": "afd53ab8-bfe9-4c3e-d55b-be7c93bc5fd1"
      },
      "outputs": [],
      "source": [
        "# install dependencies: (use cu111 because colab has CUDA 11.1)\n",
        "!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# install mmcv-full thus we could use CUDA operators\n",
        "!pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.0/index.html\n",
        "\n",
        "# Install mmdetection\n",
        "!rm -rf mmdetection\n",
        "!git clone https://github.com/open-mmlab/mmdetection.git\n",
        "%cd mmdetection\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzLTTU_AOwzu"
      },
      "source": [
        "### 1.2 - Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1bkZAYaJ7YG",
        "outputId": "11788588-e9f2-4fd5-f4ec-fa87184976ff"
      },
      "outputs": [],
      "source": [
        "from mmcv import collect_env\n",
        "collect_env()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luvy7hfnJ81E",
        "outputId": "ed29f437-f9d2-4ffc-d1bf-00f25a982072"
      },
      "outputs": [],
      "source": [
        "# Check Pytorch installation\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "\n",
        "# Check MMDetection installation\n",
        "import mmdet\n",
        "print(mmdet.__version__)\n",
        "\n",
        "# Check mmcv installation\n",
        "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
        "print(get_compiling_cuda_version())\n",
        "print(get_compiler_version())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-46oAQrRdcx"
      },
      "outputs": [],
      "source": [
        "import mmcv\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qO0tuEJNO-B0"
      },
      "source": [
        "### 1.3 - Download pretained Faster R-CNN\n",
        "\n",
        "The high-level architecture of Faster R-CNN is shown in the following picture. More details can be found in the [paper](https://arxiv.org/abs/1506.01497).\n",
        "\n",
        "![faster rcnn](https://pic1.zhimg.com/80/v2-c0172be282021a1029f7b72b51079ffe_1440w.jpg) ![mmdet](https://pic2.zhimg.com/v2-e49ebcf931b5cf424ed311338f9ff35d_b.jpg)\n",
        "\n",
        "Briefly, it uses a convolutional neural network (CNN) as backbone to extract features from an image. Then, it uses a region proposal network (RPN) to predict proposals, i.e., potential objects. After that, it uses a feature extractor to crop features for the region of interests (RoI), and uses a RoI Head to perform classification and bounding box prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezhpbDqFJ_A1",
        "outputId": "f160fba4-d25a-4420-9466-69bdd41b5e86"
      },
      "outputs": [],
      "source": [
        "# We download the pre-trained checkpoints for inference and finetuning.\n",
        "!mkdir checkpoints\n",
        "!wget -c https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_20210526_095054-1f77628b.pth \\\n",
        "      -O checkpoints/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_20210526_095054-1f77628b.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71siJjlyQ2TD"
      },
      "source": [
        "## 2 - Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfg8CF0JQ8YU"
      },
      "source": [
        "### 2.1 - Connect Google Drive to import data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_75O3EVeRFXw",
        "outputId": "c44e96ab-bc39-4c77-938a-b29f3c292e54"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Am5XICONW4_P"
      },
      "source": [
        "### 2.2 - First sneak peak on dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "OZlAco13RiF0",
        "outputId": "0025fcbf-6c90-43b1-c9d7-802a6ebf91eb"
      },
      "outputs": [],
      "source": [
        "# Let's take a look at the dataset\n",
        "img = mmcv.imread('/content/drive/MyDrive/PDSM_test/data_coco_bb/aicm01/VID000_0/image_02/000010.png')\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.imshow(mmcv.bgr2rgb(img))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RF9-3InYabe"
      },
      "source": [
        "## 3 - Building the Faster R-CNN\n",
        "Set configuration of the datatset, the model and the evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEovGQtGYxpb"
      },
      "source": [
        "### 3.1 - Import configuration of pretrained detector\n",
        "\n",
        "[INFO:](https://mmdetection.readthedocs.io/en/v2.21.0/tutorials/config.html)<br>\n",
        "For easy understanding, we recommend contributors to inherit from existing methods. For example, if some modification is made base on Faster R-CNN, user may first inherit the basic Faster R-CNN structure by specifying _base_ = ../faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py, then modify the necessary fields in the config files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbFBn9AHLIZ3"
      },
      "outputs": [],
      "source": [
        "from mmcv import Config\n",
        "cfg = Config.fromfile('/content/mmdetection/configs/faster_rcnn/faster_rcnn_r101_caffe_fpn_mstrain_3x_coco.py')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5MucpCla-Y4"
      },
      "source": [
        "Default image size: 1.920 x 540â€¬ <br>\n",
        "Resized images --> Ratio: 3,555 : 1 <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNlu77T2emBR"
      },
      "source": [
        "### 3.2 - Data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyPyTV0Uesia"
      },
      "source": [
        "![faster rcnn](https://mmdetection.readthedocs.io/en/v1.2.0/_images/data_pipeline.png)\n",
        "<br>\n",
        "[**SOURCE**](https://mmdetection.readthedocs.io/en/latest/tutorials/data_pipeline.html#design-of-data-pipelines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtHCOQ46d0ug"
      },
      "source": [
        "#### 3.2.1 - Configure train pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3AB-V56ZuoN"
      },
      "outputs": [],
      "source": [
        "# Normalize image RGB values\n",
        "# The mean and std values are decided by the pretrained models.\n",
        "# When you are finetuning with some pretrained model, you need to follow the mean and std values used for pretraining.\n",
        "cfg.img_norm_cfg = dict(mean=[103.53, 116.28, 123.675], std=[1.0, 1.0, 1.0], to_rgb=False)\n",
        "\n",
        "cfg.train_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(type='LoadAnnotations', with_bbox=True),\n",
        "    dict(\n",
        "        type='Resize', # Augmentation pipeline that resize the images and their annotations\n",
        "        img_scale=(1920/2, 540/2), # Original scale 1920x540p\n",
        "        multiscale_mode='value',\n",
        "        keep_ratio=True),\n",
        "    dict(type='RandomFlip', flip_ratio=0.5),  # The ratio or probability to flip\n",
        "    dict(type='Normalize', **cfg.img_norm_cfg),\n",
        "    dict(type='Pad', size_divisor=32), # The number the padded images should be divisible\n",
        "    dict(type='DefaultFormatBundle'), # Default format bundle to gather data in the pipeline\n",
        "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels']) # Pipeline that decides which keys in the data should be passed to the detector\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwThvPRhd562"
      },
      "source": [
        "#### 3.2.2 - Configure test pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szLzORKPd9kI"
      },
      "outputs": [],
      "source": [
        "cfg.test_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(\n",
        "        type='MultiScaleFlipAug',\n",
        "        img_scale=(1920/2, 540/2), # Decides the largest scale for testing, used for the Resize pipeline\n",
        "        flip=False,\n",
        "        transforms=[\n",
        "            dict(type='Resize', keep_ratio=True),\n",
        "            dict(type='RandomFlip'),\n",
        "            dict(type='Normalize', **cfg.img_norm_cfg),\n",
        "            dict(type='Pad', size_divisor=32),\n",
        "            dict(type='ImageToTensor', keys=['img']),\n",
        "            dict(type='Collect', keys=['img'])\n",
        "        ])\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RBjHKLhkXYx"
      },
      "source": [
        "If the concatenated dataset is used for test or evaluation, this manner supports to evaluate each dataset separately. To test the concatenated datasets as a whole, you can set separate_eval=False as below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyywMhZSNSMd"
      },
      "source": [
        "### 3.3 - Create datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "m2_-LfORVu7n",
        "outputId": "d883cc2f-f6b0-4f96-f806-e557651b7cb8"
      },
      "outputs": [],
      "source": [
        "import mmcv\n",
        "import numpy as np\n",
        "\n",
        "from mmdet.datasets.builder import DATASETS\n",
        "from mmdet.datasets.custom import CustomDataset\n",
        "from mmdet.datasets.coco import CocoDataset\n",
        "\n",
        "from .api_wrappers import COCO\n",
        "\n",
        "\n",
        "@DATASETS.register_module()\n",
        "class bbdataset(CocoDataset):\n",
        "\n",
        "    CLASSES = ('Nadelhalter', 'Knotenschieber', 'Atraum. Pinzette', 'Nervhaken', 'Klappenschere', 'None')\n",
        "\n",
        "    PALETTE = None\n",
        "\n",
        "    def load_annotations(self, ann_files):\n",
        "        \"\"\"Load annotation from COCO style annotation file.\n",
        "\n",
        "        Args:\n",
        "            ann_file (str): Path of annotation file.\n",
        "\n",
        "        Returns:\n",
        "            list[dict]: Annotation info from COCO api.\n",
        "        \"\"\"\n",
        "        data_infos = []\n",
        "        total_ann_ids = []\n",
        "        for ann_file in ann_files:\n",
        "          self.coco = COCO(ann_file)\n",
        "          # The order of returned `cat_ids` will not\n",
        "          # change with the order of the CLASSES\n",
        "          self.cat_ids = self.coco.get_cat_ids(cat_names=self.CLASSES)\n",
        "\n",
        "          self.cat2label = {cat_id: i for i, cat_id in enumerate(self.cat_ids)}\n",
        "          self.img_ids = self.coco.get_img_ids()\n",
        "          for i in self.img_ids:\n",
        "              info = self.coco.load_imgs([i])[0]\n",
        "              info['filename'] = info['file_name']\n",
        "              data_infos.append(info)\n",
        "              ann_ids = self.coco.get_ann_ids(img_ids=[i])\n",
        "              total_ann_ids.extend(ann_ids)\n",
        "          assert len(set(total_ann_ids)) == len(\n",
        "              total_ann_ids), f\"Annotation ids in '{ann_file}' are not unique!\"\n",
        "        return data_infos\n",
        "\n",
        "    def get_ann_info(self, idx):\n",
        "        \"\"\"Get COCO annotation by index.\n",
        "\n",
        "        Args:\n",
        "            idx (int): Index of data.\n",
        "\n",
        "        Returns:\n",
        "            dict: Annotation info of specified index.\n",
        "        \"\"\"\n",
        "\n",
        "        img_id = self.data_infos[idx]['id']\n",
        "        ann_ids = self.coco.get_ann_ids(img_ids=[img_id])\n",
        "        ann_info = self.coco.load_anns(ann_ids)\n",
        "        return self._parse_ann_info(self.data_infos[idx], ann_info)\n",
        "\n",
        "    def get_cat_ids(self, idx):\n",
        "        \"\"\"Get COCO category ids by index.\n",
        "\n",
        "        Args:\n",
        "            idx (int): Index of data.\n",
        "\n",
        "        Returns:\n",
        "            list[int]: All categories in the image of specified index.\n",
        "        \"\"\"\n",
        "\n",
        "        img_id = self.data_infos[idx]['id']\n",
        "        ann_ids = self.coco.get_ann_ids(img_ids=[img_id])\n",
        "        ann_info = self.coco.load_anns(ann_ids)\n",
        "        return [ann['category_id'] for ann in ann_info]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFmHYkMwNKhi"
      },
      "outputs": [],
      "source": [
        "# Set the label names\n",
        "classes = ('Nadelhalter', 'Knotenschieber', 'Atraum. Pinzette', 'Nervhaken', 'Klappenschere', 'None')\n",
        "# Modify num classes of the model in box head\n",
        "cfg.model.roi_head.bbox_head.num_classes = 6\n",
        "\n",
        "cfg.data = dict(\n",
        "    train=dict(pipeline=cfg.train_pipeline,\n",
        "               classes=classes),\n",
        "    val=dict(pipeline=cfg.test_pipeline,\n",
        "             classes=classes),\n",
        "    test=dict(pipeline=cfg.test_pipeline,\n",
        "              classes=classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8EKLg3bj8sv"
      },
      "outputs": [],
      "source": [
        "from mmdet.apis import set_random_seed\n",
        "import os.path as osp\n",
        "import mmcv\n",
        "import numpy as np\n",
        "from mmdet.datasets.builder import DATASETS\n",
        "from mmdet.datasets.custom import CustomDataset\n",
        "\n",
        "# https://github.com/open-mmlab/mmdetection/blob/master/mmdet/datasets/dataset_wrappers.py#L211\n",
        "\n",
        "# Modify dataset type and path\n",
        "cfg.dataset_type = 'bbdataset'\n",
        "cfg.data_root = '/content/drive/MyDrive/PDSM_Nils/data_coco_bb_complete/'\n",
        "\n",
        "\n",
        "def get_concat_datasets(set_type: str, num_videos: list):\n",
        "\n",
        "    # list of datasets\n",
        "    dataset = list()\n",
        "    # Set view numbers\n",
        "    num_views = [2,3]\n",
        "\n",
        "\n",
        "    if set_type == 'train':\n",
        "      pipeline = cfg.train_pipeline\n",
        "\n",
        "    if set_type == 'val':\n",
        "      pipeline = cfg.test_pipeline\n",
        "\n",
        "    if set_type == 'test':\n",
        "      pipeline = cfg.test_pipeline\n",
        "\n",
        "\n",
        "    for video in num_videos:\n",
        "      for view in num_views:\n",
        "        if video < 10:\n",
        "          dataset.append(\n",
        "              dict(type='bbdataset',\n",
        "                  pipeline=pipeline,\n",
        "                  data_root = f'/content/drive/MyDrive/PDSM_Nils/data_coco_bb_complete/aicm0{video}/VID000_0/image_0{view}',\n",
        "                  ann_file = f'/content/drive/MyDrive/PDSM_Nils/data_coco_bb_complete/aicm0{video}/VID000_0/instrument_labels_0{view}/instances_default.json',\n",
        "                  img_prefix = f'/content/drive/MyDrive/PDSM_Nils/data_coco_bb_complete/aicm0{video}/VID000_0/image_0{view}/',\n",
        "              )\n",
        "          )\n",
        "        else:\n",
        "          dataset.append(\n",
        "              dict(type='bbdataset',\n",
        "                  pipeline=pipeline,\n",
        "                  data_root = f'/content/drive/MyDrive/PDSM_Nils/data_coco_bb_complete/aicm{video}/VID000_0/image_0{view}',\n",
        "                  ann_file = f'/content/drive/MyDrive/PDSM_Nils/data_coco_bb_complete/aicm{video}/VID000_0/instrument_labels_0{view}/instances_default.json',\n",
        "                  img_prefix = f'/content/drive/MyDrive/PDSM_Nils/data_coco_bb_complete/aicm{video}/VID000_0/image_0{view}/',\n",
        "              )\n",
        "          )\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ukMs9-2vgNI"
      },
      "outputs": [],
      "source": [
        "train_videos = range(1,7)\n",
        "val_videos = range(7,9)\n",
        "test_videos = range(9,11)\n",
        "\n",
        "cfg.data = dict(\n",
        "    imgs_per_gpu=2,\n",
        "    workers_per_gpu=2,\n",
        "    train = dict(\n",
        "        type = \"ConcatDataset\",\n",
        "        datasets = get_concat_datasets(set_type='train', num_videos=train_videos)),\n",
        "    val = dict(\n",
        "        type = \"ConcatDataset\",\n",
        "        datasets = get_concat_datasets(set_type='val', num_videos=val_videos)),\n",
        "    test = dict(\n",
        "        type = \"ConcatDataset\",\n",
        "        datasets = get_concat_datasets(set_type='test', num_videos=test_videos)),\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQG7FlbG3eld"
      },
      "source": [
        "### 3.4 - Finetune R-CNN architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbDZBzfe3yWq"
      },
      "outputs": [],
      "source": [
        "# Use load_from to load the checkpoints of the pretrained model\n",
        "cfg.load_from = 'checkpoints/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_20210526_095054-1f77628b.pth'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EclhgbCmNdlY"
      },
      "source": [
        "### 3.5 - Optimizer and Evaluation metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYm-DJkrLKjL"
      },
      "outputs": [],
      "source": [
        "# The original learning rate (LR) is set for 8-GPU training.\n",
        "# We divide it by 8 since we only use one GPU.\n",
        "cfg.optimizer = dict(type='SGD', \n",
        "                     lr=0.02 / 8, \n",
        "                     momentum=0.9, \n",
        "                     weight_decay=0.0001)\n",
        "cfg.lr_config.warmup = None\n",
        "cfg.log_config.interval = 100\n",
        "\n",
        "\n",
        "# Change the evaluation metric since we use customized dataset.\n",
        "cfg.evaluation.metric = ['bbox']\n",
        "\n",
        "# We can set the evaluation interval to reduce the evaluation times\n",
        "cfg.evaluation.interval = 10\n",
        "\n",
        "# We can set the checkpoint saving interval to reduce the storage cost\n",
        "cfg.checkpoint_config.interval = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sDMjKZB3-PR"
      },
      "source": [
        "### 3.6 - Additional configs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-vCV8ab4FXn"
      },
      "outputs": [],
      "source": [
        "# Set up working dir to save files and logs.\n",
        "cfg.work_dir = '/content'\n",
        "\n",
        "# Set seed thus the results are more reproducible\n",
        "cfg.seed = 42\n",
        "set_random_seed(42, deterministic=False)\n",
        "cfg.gpu_ids = range(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0XS6Fx94msf"
      },
      "source": [
        "### 3.7 - Final config overview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxWb7OE14mUS",
        "outputId": "d2496010-f395-4dfe-900f-f3c3d22067ce"
      },
      "outputs": [],
      "source": [
        "# We can initialize the logger for training and have a look\n",
        "# at the final config used for training\n",
        "print(f'Config:\\n{cfg.pretty_text}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQpydTedgd7x"
      },
      "source": [
        "### 3.2 - Build the Faster R-CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqaSIu4aLMIS",
        "outputId": "d169b0f4-39ad-4c94-cf6a-17092d2d0a26"
      },
      "outputs": [],
      "source": [
        "from mmdet.datasets import build_dataset\n",
        "from mmdet.models import build_detector\n",
        "from mmdet.apis import train_detector\n",
        "\n",
        "cfg.device='cuda'\n",
        "\n",
        "# Build dataset\n",
        "datasets = [build_dataset(cfg.data.train)]\n",
        "\n",
        "# Build the detector\n",
        "model = build_detector(cfg.model)\n",
        "# Add an attribute for visualization convenience\n",
        "model.CLASSES = datasets[0].CLASSES\n",
        "\n",
        "print(model.CLASSES)\n",
        "\n",
        "# Create work_dir\n",
        "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itIBo9kozqww"
      },
      "outputs": [],
      "source": [
        "# We can also use tensorboard to log the training process\n",
        "cfg.log_config.hooks = [\n",
        "    dict(type='TextLoggerHook'),\n",
        "    dict(type='TensorboardLoggerHook')]\n",
        "cfg.runner.max_epochs = 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mz9He2z6gqrf"
      },
      "source": [
        "### 3.3 - Train the Faster R-CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USkjibCFgqUv",
        "outputId": "4cabb366-eb3b-4a7a-9a78-0aed74204e7b"
      },
      "outputs": [],
      "source": [
        "train_detector(model, datasets, cfg, distributed=False, validate=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBBuWvm5hsIk"
      },
      "source": [
        "## 4 - Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HG2WLWE1THWB"
      },
      "source": [
        "Load existing model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dja0vDlFTE6O"
      },
      "outputs": [],
      "source": [
        "from mmdet.apis import init_detector\n",
        "\n",
        "checkpoint_file = 'xxx'\n",
        "model = init_detector(cfg, checkpoint_file, device='cuda:0')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woYSVJ2QhxCj"
      },
      "source": [
        "### 4.1 - Predict on TEST-SET and show results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Nhq1uXcpMyPd",
        "outputId": "dcec782c-9323-4663-a3ea-9f8b619270e0"
      },
      "outputs": [],
      "source": [
        "from mmdet.apis import inference_detector, show_result_pyplot\n",
        "\n",
        "for i in range(10,100):\n",
        "  try:\n",
        "    img = mmcv.imread(f'/content/drive/MyDrive/PDSM/data_coco_bb/aicm08/VID000_0/image_02/0000{i}.png')\n",
        "  except:\n",
        "    continue\n",
        "  model.cfg = cfg\n",
        "  result = inference_detector(model, img)\n",
        "  show_result_pyplot(model, img, result)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "PDSM_Mono_Faster_R-CNN.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
